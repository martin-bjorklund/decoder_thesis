{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcdq4-4n5LtU"
      },
      "source": [
        "Code for Martin Bj√∂rklund's 2024 master thesis in mathematical statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu14Q4stNWoN"
      },
      "source": [
        "# Decoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j56MFiwNkb2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "'''\n",
        "Each DecoderBlock decodes one block of ResNet 18.\n",
        "\n",
        "For decoding the first checkpoint, one DecoderBlock is needed,\n",
        "for decoding the second one two are needed and so on. Each block\n",
        "contains 4 transposed convolutions and 2 residual connections.\n",
        "\n",
        "Note that the dimensionality changes only in the final transposed convolution.\n",
        "'''\n",
        "#Decodes each block (two \"BasicBlocks\")\n",
        "class DecoderBlock(nn.Module):\n",
        "  #Constructor\n",
        "  def __init__(self, in_channels, out_channels, final_transpose_stride = 1,\n",
        "               transpose_padding = 1, output_padding = 0, device = None):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "\n",
        "    #First \"BasicBlock\" decoder\n",
        "\n",
        "    #First deconvolution\n",
        "    #NOTE: \"padding argument [in transpose convolution] effectively adds dilation * (kernel_size - 1) - padding amount of\n",
        "    #      zero padding to both sizes of the input.\" (documentation)\n",
        "    self.deconv1 = nn.ConvTranspose2d(in_channels, in_channels, kernel_size = 3,\n",
        "                                      stride = 1, padding = transpose_padding,\n",
        "                                      bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "    #Second deconvolution\n",
        "    self.deconv2 = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=3, #Changing the number of channels\n",
        "                                      stride=1, padding=transpose_padding,\n",
        "                                      bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "    #Residual connection\n",
        "    #A 1x1 convolution would be needed here if the stride is not 1\n",
        "    self.shortcut1 = nn.Sequential()\n",
        "\n",
        "    #Second \"BasicBlock\"\n",
        "    self.deconv3 = nn.ConvTranspose2d(in_channels, in_channels, kernel_size = 3,\n",
        "                                      stride = 1, padding = transpose_padding,\n",
        "                                      bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "    #NOTE: THIS IS WHERE WE CHANGE THE DIMENSIONS AND CHANNELS\n",
        "    #NOTE: For decoding the second (and later blocks) block, this Transposed convolution is not exactly the\n",
        "    #      one corresponding to the convolution used in Resnet18, as that type of transposed convolution\n",
        "    #      does not seem to be implemented in PyTorch.\n",
        "    self.deconv4 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size = 3,\n",
        "                                      stride = final_transpose_stride,\n",
        "                                      padding=transpose_padding,\n",
        "                                      output_padding = output_padding, bias=False)\n",
        "    self.bn4 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    #Second residual connection\n",
        "    self.shortcut2 = nn.Sequential()\n",
        "    if in_channels != out_channels or final_transpose_stride != 1:\n",
        "      self.shortcut2 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=1,\n",
        "                           stride = final_transpose_stride, padding = 0,\n",
        "                           output_padding = 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels)\n",
        "      )\n",
        "\n",
        "  #Forward pass method\n",
        "  def forward(self, input):\n",
        "    #First \"Basic block\"\n",
        "    sub_block_1 = F.relu(self.bn1(self.deconv1(input)))\n",
        "    sub_block_1 = self.bn2(self.deconv2(sub_block_1))\n",
        "    sub_block_1 += self.shortcut1(input) #Adding residual connection\n",
        "    sub_block_1 = F.relu(sub_block_1)\n",
        "\n",
        "    #Second \"Basic Block\"\n",
        "    out = F.relu(self.bn3(self.deconv3(sub_block_1)))\n",
        "    out = self.bn4(self.deconv4(out))\n",
        "    out += self.shortcut2(sub_block_1) #Adding second residual connection\n",
        "    out = F.relu(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "#Class for the whole decoder\n",
        "class ResNetDecoder(nn.Module):\n",
        "  def __init__(self, n_blocks, n_channels_in, n_channels_out, strides,\n",
        "               final_stride, final_padding, output_padding, checkpoint_n = 0):\n",
        "    '''\n",
        "    Args:\n",
        "      n_blocks (int): Number of DecoderBlocks needed, 1 <= n_blocks <= 4.\n",
        "\n",
        "      n_channels_in: A list, where each element is the number of input channels to each\n",
        "                    decoder block. (i.e. the number of output channels of\n",
        "                    each resnet block, in reverse order)\n",
        "\n",
        "      n_channels_out: A list where each element is the number of output channels of each\n",
        "                      decoder block.\n",
        "\n",
        "      strides: A list. The stride to be used in the final deconvolution of each block.\n",
        "\n",
        "      final_stride, final_padding: Stride and padding to be used in the final\n",
        "                                  deconvolution of the decoder\n",
        "                                  When decoding only the first block, stride and\n",
        "                                  padding should both be 1. (in our first experiment)\n",
        "\n",
        "      output_padding (list): Sets the output_padding to be used in the final\n",
        "                            deconvolution of each DecoderBlock\n",
        "\n",
        "      checkpoint_n (int): Integer representing the checkpoint number. Only required\n",
        "                          for checkpoints 5 and 6.\n",
        "    '''\n",
        "    super(ResNetDecoder, self).__init__()\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    self.checkpoint_n = checkpoint_n\n",
        "\n",
        "    #Last checkpoint requires a linear layer\n",
        "    if checkpoint_n == 6:\n",
        "      self.linear = nn.Linear(10, 512)\n",
        "\n",
        "    #if checkpoint_n >= 5:\n",
        "      self.register_parameter('unpool_params', None)\n",
        "\n",
        "    for i in range(0, n_blocks):\n",
        "      layers.append(DecoderBlock(n_channels_in[i], n_channels_out[i],\n",
        "                                 final_transpose_stride=strides[i],\n",
        "                                 output_padding = output_padding[i]))\n",
        "\n",
        "    self.decoder_blocks = nn.Sequential(*layers)\n",
        "\n",
        "    self.deconv_final = nn.ConvTranspose2d(in_channels=n_channels_out[-1], out_channels = 3,\n",
        "                                           stride = final_stride, padding = final_padding,\n",
        "                                           kernel_size = 3)\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = input\n",
        "\n",
        "    #assuming dimension 0 is minibatch, we need to go from 2d to 3d\n",
        "    if self.checkpoint_n == 6:\n",
        "      #Fully connected layer\n",
        "      #dims (minibatch, 10)\n",
        "      out = out.view(-1, 1, out.size(1)) #dims (minibatch, 1, 10)\n",
        "      out = self.linear(out) #dims (minibatch, 1, 512)\n",
        "      out = out.view(-1, 512, 1).unsqueeze(3) #dims (minibatch, 512, 1, 1)\n",
        "\n",
        "    #If we are decoding checkpoint 5 or 6, we need to go from (512, 1, 1) to\n",
        "    #(512, 4, 4) (we do unpooling)\n",
        "    if self.checkpoint_n >= 5:\n",
        "      out = out.expand(-1, 512, 4, 4) #dims (minibatch, 512, 4, 4)\n",
        "      #Introducing trainable parameters for the unpooling\n",
        "      #We initialize them as 1, since setting them to 1 would mean the average\n",
        "      #pooling is inversed (almost)\n",
        "      self.unpool_params = nn.Parameter(torch.ones(out.size()).to(device))\n",
        "      out = out * self.unpool_params\n",
        "\n",
        "    out = self.decoder_blocks(out)\n",
        "    out = self.deconv_final(out)\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPaZFmr9-mUW"
      },
      "source": [
        "# Loading Target Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdfRvX_VBQJQ"
      },
      "outputs": [],
      "source": [
        "# CUDA for PyTorch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True #Finds best algorithms automatically? Somehow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-jjw6AE-lZ1",
        "outputId": "d4e6362a-a1e6-4f7e-d72e-cb919478941a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = \"/content/drive/My Drive/Colab Notebooks/Examensarbete/Data/\"\n",
        "\n",
        "targets_training = torch.load(data_path + \"images_train.pt\")\n",
        "targets_testing = torch.load(data_path + \"images_test.pt\")\n",
        "train_labels = torch.load(\"/content/drive/My Drive/Colab Notebooks/Examensarbete/train_labels.pt\")\n",
        "test_labels = torch.load(\"/content/drive/My Drive/Colab Notebooks/Examensarbete/test_labels.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "b3GtTHveXU56",
        "outputId": "f563d163-cdaf-4522-f256-ff817520b614"
      },
      "outputs": [],
      "source": [
        "# @title Plotting Example Images {display-mode: \"form\"}\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = [\"airplane\",\n",
        "           \"automobile\",\n",
        "           \"bird\",\n",
        "           \"cat\",\n",
        "           \"deer\",\n",
        "           \"dog\",\n",
        "           \"frog\",\n",
        "           \"horse\",\n",
        "           \"ship\",\n",
        "           \"truck\"]\n",
        "\n",
        "train_labels_list = list(train_labels.numpy())\n",
        "train_labels_str = [classes[i] for i in train_labels_list]\n",
        "\n",
        "class_indices_list = [train_labels_str.index(elem) for elem in set(train_labels_str)]\n",
        "class_indices = torch.tensor(class_indices_list).reshape(2, 5)\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 3))\n",
        "\n",
        "for row in range(0, 2):\n",
        "  for col in range(0, 5):\n",
        "    img_idx = class_indices[row, col]\n",
        "\n",
        "    #The tensors are of dimensions (3, 32, 32), but imshow expects\n",
        "    #(32, 32, 3), so we need to permute the tensor\n",
        "    image = targets_training[img_idx].permute(1, 2, 0)\n",
        "    # Normalizing the pixel values (0-1 float expected by imshow)\n",
        "    image = (image - image.min()) / (image.max() - image.min())\n",
        "\n",
        "    axes[row, col].imshow(image)\n",
        "    axes[row, col].spines['top'].set_visible(False)\n",
        "    axes[row, col].spines['right'].set_visible(False)\n",
        "    axes[row, col].spines['bottom'].set_visible(False)\n",
        "    axes[row, col].spines['left'].set_visible(False)\n",
        "    axes[row, col].set_xlabel(train_labels_str[img_idx],\n",
        "                          rotation=0, ha = \"center\", size = \"medium\",\n",
        "                              weight = \"bold\")\n",
        "\n",
        "plt.subplots_adjust(left=0, right=1, bottom=0, top=1, wspace=-0.861, hspace=0.28)\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBjNOoSrSedK",
        "outputId": "16257663-b3d4-42a9-bb40-d4a8df110617"
      },
      "outputs": [],
      "source": [
        "print(class_indices_list)\n",
        "print(class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fX0Wy-WRwck"
      },
      "source": [
        "# Functions for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt6Dvg-a2Yvu"
      },
      "source": [
        "## Training and validation functions\n",
        "\n",
        "Functions for doing a training and a testing step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjXZLPgARgTo"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "\n",
        "#Function for doing a training step\n",
        "def train_step(model, training_DataLoader, device, loss_fn, optimizer):\n",
        "  \"Trains one epoch of the model.\"\n",
        "\n",
        "  # Puting model in training mode\n",
        "  model.train()\n",
        "\n",
        "  # Torch tensor for storing loss for each batch\n",
        "  train_loss_tensor = torch.zeros(len(training_DataLoader))\n",
        "\n",
        "  for i, (local_batch, local_targets) in enumerate(training_DataLoader):\n",
        "    # Transfer to GPU\n",
        "    local_batch, local_targets = local_batch.to(device), local_targets.to(device)\n",
        "\n",
        "    # 1. Forward pass on training data\n",
        "    y_pred = model(local_batch)\n",
        "\n",
        "    # 2. Calculating and accumulating the loss\n",
        "    temp_loss = loss_fn(y_pred, local_targets)\n",
        "    train_loss_tensor[i] = temp_loss.item()\n",
        "\n",
        "    # 3. Setting gradient to zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    temp_loss.backward()\n",
        "\n",
        "    # 5. Progressing the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "  #Standard error of the training loss\n",
        "  train_loss_se = train_loss_tensor.std().item() / len(train_loss_tensor)\n",
        "\n",
        "  #Getting average loss per batch\n",
        "  train_loss = train_loss_tensor.mean().item()\n",
        "\n",
        "  return train_loss, train_loss_se\n",
        "\n",
        "#Function for doing a validation step\n",
        "def test_step(model, testing_DataLoader, device, loss_fn):\n",
        "  \"Tests one epoch of the model.\"\n",
        "\n",
        "  #Putting model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  #Empty tensor for storing loss values\n",
        "  test_loss_tensor = torch.zeros(len(testing_DataLoader))\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    #Looping over batches\n",
        "    for i, (local_batch, local_targets) in enumerate(testing_DataLoader):\n",
        "      # Transfer to GPU\n",
        "      local_batch, local_targets = local_batch.to(device), local_targets.to(device)\n",
        "\n",
        "      #Forward pass\n",
        "      preds = model(local_batch)\n",
        "\n",
        "      #Calculating and accumulating loss\n",
        "      temp_loss = loss_fn(preds, local_targets)\n",
        "      test_loss_tensor[i] = temp_loss.item()\n",
        "\n",
        "  #Calculating average loss\n",
        "  test_loss = test_loss_tensor.mean().item()\n",
        "  test_loss_se = test_loss_tensor.std().item() / len(test_loss_tensor)\n",
        "\n",
        "  return test_loss, test_loss_se"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x_xiLcpk-aq"
      },
      "outputs": [],
      "source": [
        "#Training and validation function\n",
        "def train_model(model, model_save_name, training_DataLoader, testing_DataLoader,\n",
        "                device, loss_fn, optimizer, patience = 10, max_epochs = 30,\n",
        "                save_path = \"/content/drive/My Drive/Colab Notebooks/Examensarbete/Model parameters/\"):\n",
        "  \"\"\"\n",
        "    Trains a PyTorch model for a number of epochs, implements early stopping.\n",
        "    Also plots the validation curve after each epoch.\n",
        "\n",
        "    Args:\n",
        "        model: The PyTorch model.\n",
        "        model_save_name (str): Name to use when saving the parameters of the best model.\n",
        "        training_DataLoader: DataLoader for training\n",
        "        testing_DataLoader: DataLoader for validation\n",
        "        device: Device to store tensors on.\n",
        "        loss_fn: Loss function to use\n",
        "        optimizer: Optimizer to use\n",
        "        patience (int): Patience used for early stopping.\n",
        "        max_epochs (int): Maximum number of epochs to run.\n",
        "        save_path (str): Where to store the best parameter values.\n",
        "  \"\"\"\n",
        "  import time\n",
        "\n",
        "  #Empty lists for tracking loss and epochs\n",
        "  train_loss_values = []\n",
        "  test_loss_values = []\n",
        "  train_loss_se = []\n",
        "  test_loss_se = []\n",
        "  epoch_count = []\n",
        "\n",
        "  #For early stopping\n",
        "  best_loss = None\n",
        "  best_train_loss = None\n",
        "  early_stop_count = 0\n",
        "\n",
        "  # Loop over epochs\n",
        "  for epoch in range(1, max_epochs + 1):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_loss_se = train_step(model, training_DataLoader, device, loss_fn,\n",
        "                            optimizer)\n",
        "\n",
        "    test_loss, test_loss_se = test_step(model, testing_DataLoader, device, loss_fn)\n",
        "\n",
        "    #Printing results\n",
        "    epoch_count.append(epoch)\n",
        "    train_loss_values.append(train_loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    end_time = round(time.time() - start_time, 2)\n",
        "\n",
        "    print(f\"Epoch: {epoch} | Time: {end_time} seconds \\\n",
        "          \\n| MSE Train Loss: {train_loss} SE: {train_loss_se} \\\n",
        "          \\n| MSE Test Loss: {test_loss} SE: {test_loss_se}\")\n",
        "\n",
        "    # Ploting the loss curves\n",
        "    plt.errorbar(epoch_count, train_loss_values, train_loss_se, label=\"Train loss\")\n",
        "    plt.errorbar(epoch_count, test_loss_values, test_loss_se, label=\"Validation loss\")\n",
        "    plt.title(\"Training and validation loss curves\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    if best_train_loss == None or train_loss < best_train_loss:\n",
        "      torch.save(model.state_dict(), save_path + model_save_name + \"_best_trainloss.pt\")\n",
        "\n",
        "    #Early stopping\n",
        "    if best_loss == None or test_loss < best_loss:\n",
        "      best_loss = test_loss\n",
        "      early_stop_count = 0\n",
        "      best_epoch = epoch\n",
        "      #Saving best model parameters\n",
        "      torch.save(model.state_dict(), save_path + model_save_name + \".pt\")\n",
        "\n",
        "    else:\n",
        "      early_stop_count += 1\n",
        "      if early_stop_count >= patience:\n",
        "        print(f\"Validation loss not decreasing. Stopping early. Best epoch: {best_epoch}\")\n",
        "        break\n",
        "\n",
        "  return train_loss_values, test_loss_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXBC3Tbxg7Ig"
      },
      "source": [
        "Loss function (used for all decoders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjQ8LBE8g6Yp"
      },
      "outputs": [],
      "source": [
        "#Loss function\n",
        "loss_fn = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuIbsLTh3DNV"
      },
      "source": [
        "## Function for plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-JsxkTC3Csb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming that the images are of shape (3, 32, 32)\n",
        "def plot_generated_imgs(model, left_col_data, right_col_data,\n",
        "                        num_images_to_plot = 10, figsize = (15, 6),\n",
        "                        img_indices_to_plot = None):\n",
        "  \"\"\"\n",
        "  Plots generated and original images.\n",
        "\n",
        "  Args:\n",
        "    model: The PyTorch model to be used.\n",
        "    left_col_data (tensor): Data for the left column images (original data).\n",
        "    right_col_data (tensor): Target data. Expects (3, 32, 32) tensors.\n",
        "    num_imgs_plotted (int): Number of images to plot.\n",
        "    img_indices_to_plot (list): Optional. Indices of specific images to be decoded.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  if img_indices_to_plot != None:\n",
        "    indices = img_indices_to_plot\n",
        "  else:\n",
        "    indices = range(num_images_to_plot)\n",
        "\n",
        "  fig, axes = plt.subplots(len(indices), 2, figsize = figsize)\n",
        "\n",
        "  # Plotting original images (left column)\n",
        "  for j in indices:\n",
        "    original_image = left_col_data[j].permute(1, 2, 0)\n",
        "    original_image = (original_image - original_image.min()) / (original_image.max() - original_image.min())\n",
        "    axes[j, 0].imshow(original_image.cpu().numpy()) #Images need to be stored on CPU\n",
        "    axes[j, 0].axis('off')\n",
        "\n",
        "  #Plotting decoded images (right column)\n",
        "  for i in indices:\n",
        "    #Selecting observation i, and then adding back the missing dimension\n",
        "    observation = right_col_data[i].unsqueeze(0)\n",
        "    #Running model to decode an observation\n",
        "    with torch.no_grad():\n",
        "      decoded_image = model(observation)\n",
        "\n",
        "    # The tensors are of dimensions (3, 32, 32), but imshow expects (32, 32, 3)\n",
        "    decoded_image = decoded_image.squeeze(0).permute(1, 2, 0)\n",
        "    # Normalizing the pixel values (0-1 float expected by imshow)\n",
        "    decoded_image = (decoded_image - decoded_image.min()) / (decoded_image.max() - decoded_image.min())\n",
        "    axes[i, 1].imshow(decoded_image.cpu().numpy())\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "  plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwOGLOswMh1O"
      },
      "source": [
        "## Function for getting error of individual predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGjoYI9yc7NC"
      },
      "outputs": [],
      "source": [
        "def get_squared_error(model, features, targets):\n",
        "    \"\"\"\"\n",
        "    Calculates squared error for each individual sample, based on model.\n",
        "    \"\"\"\n",
        "    sq_er = nn.MSELoss(reduction = \"sum\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    losses = torch.zeros(targets.size(0))\n",
        "\n",
        "    #Calculating loss for each image\n",
        "    for i in range(targets.size(0)):\n",
        "        with torch.no_grad():\n",
        "            pred = model(features[i].unsqueeze(0)).cpu()\n",
        "\n",
        "        losses[i] = sq_er(pred.squeeze(0), targets[i])\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMaGc_f6EDhs"
      },
      "outputs": [],
      "source": [
        "err_save_path = \"/content/drive/My Drive/Colab Notebooks/Examensarbete/Individual errors/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMxzra6v8gK7"
      },
      "outputs": [],
      "source": [
        "save_path = \"/content/drive/My Drive/Colab Notebooks/Examensarbete/Model parameters/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7kqfaLvp7JH"
      },
      "source": [
        "# Loading ResNet-18 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkWK09z8p8-e"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "\n",
        "Code in this cell from:\n",
        "    https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqrgnbl0p_mP"
      },
      "outputs": [],
      "source": [
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "resnet = ResNet18().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCk4FuUxqCzH"
      },
      "outputs": [],
      "source": [
        "resnet_params = torch.load(save_path + \"resnet_params.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIgZsbWqqUSe",
        "outputId": "ca89b4c7-95fb-4df5-b46a-6aeec35f206c"
      },
      "outputs": [],
      "source": [
        "#Changing keys (resnet_params.pkl keys start with the name \"module.\")\n",
        "resnet_params = OrderedDict([(k.replace(\"module.\", \"\"), v) for k, v in resnet_params.items()])\n",
        "\n",
        "resnet.load_state_dict(resnet_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpM-hJIgqt86"
      },
      "source": [
        "## Function for making ResNet Prediction on Decoded Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P21XEITvq0nH"
      },
      "outputs": [],
      "source": [
        "def decoded_predictions(data, decoder, prediction_model):\n",
        "  \"\"\"\n",
        "    Decodes images in data using decoder, then returns output of\n",
        "    prediction_model when run on decoded images.\n",
        "  \"\"\"\n",
        "  decoder.eval()\n",
        "  prediction_model.eval()\n",
        "  n_obs = data.size(0)\n",
        "\n",
        "  #Empty tensors for predictions\n",
        "  decoded_images = torch.zeros(n_obs, 3, 32, 32).to(device)\n",
        "  preds = torch.zeros(n_obs, 10).to(device)\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for i in range(n_obs):\n",
        "      datapoint = data[i].to(device)\n",
        "      decoded_images[i] = decoder(datapoint.unsqueeze(0))\n",
        "      preds[i] = prediction_model(decoded_images[i].unsqueeze(0))\n",
        "\n",
        "  return preds.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQBqfpkX3tdZ"
      },
      "source": [
        "# Training and Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qiqt5aOi2tnk"
      },
      "source": [
        "## Checkpoint 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlEYC_Fl8KwQ"
      },
      "outputs": [],
      "source": [
        "#Loading feature tensors\n",
        "features_training_1 = torch.load(data_path + \"c_1_train.pt\")\n",
        "features_testing_1 = torch.load(data_path + \"c_1_test.pt\")\n",
        "\n",
        "# Parameters for the dataloaders\n",
        "params = {'batch_size': 10,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "# Creating datasets and dataloaders\n",
        "training_set = torch.utils.data.TensorDataset(features_training_1, targets_training)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = torch.utils.data.TensorDataset(features_testing_1, targets_testing)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19NkV0442WmB"
      },
      "outputs": [],
      "source": [
        "#Initializing model and moving it to the GPU\n",
        "decoder_1 = ResNetDecoder(n_blocks = 1, n_channels_in = [64], n_channels_out = [64],\n",
        "                          strides = [1], final_stride=1, final_padding = 1,\n",
        "                          output_padding = [0]).to(device)\n",
        "\n",
        "decoder_1 = torch.nn.DataParallel(decoder_1)\n",
        "\n",
        "#Trying default parameter values for Adam\n",
        "optimizer = optim.Adam(decoder_1.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yV09eK0ptbRA",
        "outputId": "6e906d7d-dc83-499c-8c3d-e536b54b1095"
      },
      "outputs": [],
      "source": [
        "#Training the model\n",
        "train_model(decoder_1, \"decoder_1_2\", training_generator, validation_generator,\n",
        "                device, loss_fn, optimizer, patience = 10, max_epochs = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN5QJbQbG-U_"
      },
      "source": [
        "### Visualizing Images (Original and Decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFbvQQaKt7XW",
        "outputId": "0e358539-b92a-4744-fedb-6579f101f8f0"
      },
      "outputs": [],
      "source": [
        "decoder_1.load_state_dict(torch.load(save_path + \"decoder_1_3.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8g_xVebQIGs1",
        "outputId": "53995689-c311-4e95-d64c-e7bb209995aa"
      },
      "outputs": [],
      "source": [
        "#Training data\n",
        "plot_generated_imgs(decoder_1, targets_training, features_training_1,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kaSObP0fG9Y0",
        "outputId": "305790f2-9243-4678-c4ff-f86ce63084a8"
      },
      "outputs": [],
      "source": [
        "#Validation data\n",
        "plot_generated_imgs(decoder_1, targets_testing, features_testing_1,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-4bNoDPeseY"
      },
      "source": [
        "### Getting error for each image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSRBiRv4exCT"
      },
      "outputs": [],
      "source": [
        "checkpoint_1_train_err = get_squared_error(decoder_1, features_training_1, targets_training)\n",
        "checkpoint_1_test_err = get_squared_error(decoder_1, features_testing_1, targets_testing)\n",
        "\n",
        "torch.save(checkpoint_1_train_err, err_save_path + \"checkpoint_1_train_err.pt\")\n",
        "torch.save(checkpoint_1_test_err, err_save_path + \"checkpoint_1_test_err.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQH3ipY5_Ycw"
      },
      "outputs": [],
      "source": [
        "#freeing up memory\n",
        "del(checkpoint_1_train_err)\n",
        "del(checkpoint_1_test_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OWSEXE13Ewg"
      },
      "source": [
        "### Running Resnet on checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gma4tYs83I9s"
      },
      "outputs": [],
      "source": [
        "c_1_resnet = decoded_predictions(features_testing_1, decoder_1, resnet)\n",
        "\n",
        "c_1_resnet_loss = F.cross_entropy(c_1_resnet, test_labels)\n",
        "c_1_resnet_preds = F.softmax(c_1_resnet, dim = 1).argmax(dim = 1)\n",
        "c_1_resnet_acc = ((c_1_resnet_preds == test_labels).sum() / 10000).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l33npdxPunxE"
      },
      "source": [
        "## Checkpoint 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coXfMmOkis9w"
      },
      "outputs": [],
      "source": [
        "#Loading feature tensors\n",
        "features_training_2 = torch.load(data_path + \"c_2_train.pt\")\n",
        "features_testing_2 = torch.load(data_path + \"c_2_test.pt\")\n",
        "\n",
        "# Parameters for the dataloaders\n",
        "params = {'batch_size': 10,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "# Creating datasets and dataloaders\n",
        "training_set = torch.utils.data.TensorDataset(features_training_2, targets_training)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = torch.utils.data.TensorDataset(features_testing_2, targets_testing)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diD4YMRkHgA6"
      },
      "outputs": [],
      "source": [
        "#Initializing model and moving it to the GPU\n",
        "decoder_2 = ResNetDecoder(n_blocks = 2, n_channels_in = [128, 64],\n",
        "                          n_channels_out = [64, 64], strides = [2, 1],\n",
        "                          final_stride=1, final_padding = 1,\n",
        "                          output_padding = [1, 0]).to(device)\n",
        "\n",
        "decoder_2 = torch.nn.DataParallel(decoder_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyEvTksuitxo"
      },
      "outputs": [],
      "source": [
        "#Loading weights from decoder_1\n",
        "state_dict_1 = decoder_1.state_dict()\n",
        "#Changing keys (necessary for loading weights into decoder_2)\n",
        "state_dict_1 = OrderedDict([(k.replace(\"blocks.0\", \"blocks.1\"), v) for k, v in state_dict_1.items()])\n",
        "\n",
        "#Initializing weights for decoder_2\n",
        "decoder_2.load_state_dict(state_dict_1, strict = False)\n",
        "\n",
        "#Trying default parameter values for Adam\n",
        "optimizer = optim.Adam(decoder_2.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jg8Nb5N3Oezr",
        "outputId": "72a60018-cd6c-417a-f98e-d759ce87ed68"
      },
      "outputs": [],
      "source": [
        "#Training the model\n",
        "train_model(decoder_2, \"decoder_2\", training_generator, validation_generator,\n",
        "                device, loss_fn, optimizer, patience = 10, max_epochs = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SThEqwF0OmLe"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJwmmZKXvA4s",
        "outputId": "57dfd3f6-6da9-43e4-a966-dc4cfaed63f0"
      },
      "outputs": [],
      "source": [
        "decoder_2.load_state_dict(torch.load(save_path + \"decoder_2_2.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sj8Syas-IoMk",
        "outputId": "a0bea180-4be2-4d41-d972-349746da0dbf"
      },
      "outputs": [],
      "source": [
        "#Training data\n",
        "plot_generated_imgs(decoder_2, targets_training, features_training_2,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o7tmu7DQOF6H",
        "outputId": "72486627-8815-435f-b2d1-6488fbb6e0e6"
      },
      "outputs": [],
      "source": [
        "#Validation data\n",
        "plot_generated_imgs(decoder_2, targets_testing, features_testing_2,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t9mUPNPe2FP"
      },
      "source": [
        "### Getting errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qivkjf9Ae31z"
      },
      "outputs": [],
      "source": [
        "checkpoint_2_train_err = get_squared_error(decoder_2, features_training_2, targets_training)\n",
        "checkpoint_2_test_err = get_squared_error(decoder_2, features_testing_2, targets_testing)\n",
        "\n",
        "torch.save(checkpoint_2_train_err, err_save_path + \"checkpoint_2_train_err.pt\")\n",
        "torch.save(checkpoint_2_test_err, err_save_path + \"checkpoint_2_test_err.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_SY-lXR_fNL"
      },
      "outputs": [],
      "source": [
        "#freeing up memory\n",
        "del(checkpoint_2_train_err)\n",
        "del(checkpoint_2_test_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6eEoXey8cuN"
      },
      "source": [
        "### Running Resnet on checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-V9YeZH8ewf"
      },
      "outputs": [],
      "source": [
        "c_2_resnet = decoded_predictions(features_testing_2, decoder_2, resnet)\n",
        "\n",
        "c_2_resnet_loss = F.cross_entropy(c_2_resnet, test_labels)\n",
        "c_2_resnet_preds = F.softmax(c_2_resnet, dim = 1).argmax(dim = 1)\n",
        "c_2_resnet_acc = ((c_2_resnet_preds == test_labels).sum() / 10000).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umF19pUSP2_i"
      },
      "source": [
        "## Checkpoint 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29UokdxFVFLb"
      },
      "outputs": [],
      "source": [
        "#Loading feature tensors\n",
        "features_training_3 = torch.load(data_path + \"c_3_train.pt\")\n",
        "features_testing_3 = torch.load(data_path + \"c_3_test.pt\")\n",
        "\n",
        "# Parameters for the dataloaders\n",
        "params = {'batch_size': 10,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "# Creating datasets and dataloaders\n",
        "training_set = torch.utils.data.TensorDataset(features_training_3, targets_training)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = torch.utils.data.TensorDataset(features_testing_3, targets_testing)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYkiTz6kHnjt"
      },
      "outputs": [],
      "source": [
        "#Initializing model and moving it to the GPU\n",
        "decoder_3 = ResNetDecoder(n_blocks = 3, n_channels_in = [256, 128, 64],\n",
        "                          n_channels_out = [128, 64, 64], strides = [2, 2, 1],\n",
        "                          final_stride=1, final_padding = 1,\n",
        "                          output_padding = [1, 1, 0]).to(device)\n",
        "\n",
        "decoder_3 = torch.nn.DataParallel(decoder_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-leHpH6nvPTm"
      },
      "outputs": [],
      "source": [
        "#Loading weights from decoder_2\n",
        "state_dict_2 = decoder_2.state_dict()\n",
        "#Changing keys (necessary for loading weights into decoder_3)\n",
        "state_dict_2 = OrderedDict([(k.replace(\"blocks.1\", \"blocks.2\"), v) for k, v in state_dict_2.items()])\n",
        "state_dict_2 = OrderedDict([(k.replace(\"blocks.0\", \"blocks.1\"), v) for k, v in state_dict_2.items()])\n",
        "\n",
        "#Initializing weights for decoder_3\n",
        "decoder_3.load_state_dict(state_dict_2, strict = False)\n",
        "\n",
        "#Trying default parameter values for Adam\n",
        "optimizer = optim.Adam(decoder_3.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W32KMGydzNZ1",
        "outputId": "70b999b7-aa23-4e7e-c8cb-6600c189a3b1"
      },
      "outputs": [],
      "source": [
        "#Training the model\n",
        "train_model(decoder_3, \"decoder_3\", training_generator, validation_generator,\n",
        "                device, loss_fn, optimizer, patience = 20, max_epochs = 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqXxD_51zX3X"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DQi9qd9znyy",
        "outputId": "40729c2f-b108-4c9e-8e0c-40a42a1fff6b"
      },
      "outputs": [],
      "source": [
        "decoder_3.load_state_dict(torch.load(save_path + \"decoder_3_2.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SfMAaEPVIrtj",
        "outputId": "328aac46-655c-420f-9fa6-d01e6a09d551"
      },
      "outputs": [],
      "source": [
        "#Training data\n",
        "plot_generated_imgs(decoder_3, targets_training, features_training_3,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gVZB1tQNzemU",
        "outputId": "95ea4efe-df77-40fa-bff4-f537e1e05e6d"
      },
      "outputs": [],
      "source": [
        "#Validation data\n",
        "plot_generated_imgs(decoder_3, targets_testing, features_testing_3,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccq4J4iEe_ix"
      },
      "source": [
        "### Getting errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChFB0Iz3fAqD"
      },
      "outputs": [],
      "source": [
        "checkpoint_3_train_err = get_squared_error(decoder_3, features_training_3, targets_training)\n",
        "checkpoint_3_test_err = get_squared_error(decoder_3, features_testing_3, targets_testing)\n",
        "\n",
        "torch.save(checkpoint_3_train_err, err_save_path + \"checkpoint_3_train_err.pt\")\n",
        "torch.save(checkpoint_3_test_err, err_save_path + \"checkpoint_3_test_err.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0DR2dUd_wNs"
      },
      "outputs": [],
      "source": [
        "#freeing up memory\n",
        "del(checkpoint_3_train_err)\n",
        "del(checkpoint_3_test_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8GhNBGO86JR"
      },
      "source": [
        "### Running Resnet on Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZSik3yI89eZ"
      },
      "outputs": [],
      "source": [
        "c_3_resnet = decoded_predictions(features_testing_3, decoder_3, resnet)\n",
        "\n",
        "c_3_resnet_loss = F.cross_entropy(c_3_resnet, test_labels)\n",
        "c_3_resnet_preds = F.softmax(c_3_resnet, dim = 1).argmax(dim = 1)\n",
        "c_3_resnet_acc = ((c_3_resnet_preds == test_labels).sum() / 10000).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO1uXuS2P879"
      },
      "source": [
        "## Checkpoint 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGpKxiNoP70x"
      },
      "outputs": [],
      "source": [
        "#Loading feature tensors\n",
        "features_training_4 = torch.load(data_path + \"c_4_train.pt\")\n",
        "features_testing_4 = torch.load(data_path + \"c_4_test.pt\")\n",
        "\n",
        "# Parameters for the dataloaders\n",
        "params = {'batch_size': 10,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "# Creating datasets and dataloaders\n",
        "training_set = torch.utils.data.TensorDataset(features_training_4, targets_training)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = torch.utils.data.TensorDataset(features_testing_4, targets_testing)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id_JQMOiHtcO"
      },
      "outputs": [],
      "source": [
        "#Initializing model and moving it to the GPU\n",
        "decoder_4 = ResNetDecoder(n_blocks = 4, n_channels_in = [512, 256, 128, 64],\n",
        "                          n_channels_out = [256, 128, 64, 64],\n",
        "                          strides = [2, 2, 2, 1], final_stride=1,\n",
        "                          final_padding = 1,\n",
        "                          output_padding = [1, 1, 1, 0]).to(device)\n",
        "\n",
        "decoder_4 = torch.nn.DataParallel(decoder_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ombjrcXH0Kqj"
      },
      "outputs": [],
      "source": [
        "#Loading weights from decoder_3\n",
        "state_dict_3 = decoder_3.state_dict()\n",
        "#Changing keys (necessary for loading weights into decoder_4)\n",
        "state_dict_3 = OrderedDict([(k.replace(\"blocks.2\", \"blocks.3\"), v) for k, v in state_dict_3.items()])\n",
        "state_dict_3 = OrderedDict([(k.replace(\"blocks.1\", \"blocks.2\"), v) for k, v in state_dict_3.items()])\n",
        "state_dict_3 = OrderedDict([(k.replace(\"blocks.0\", \"blocks.1\"), v) for k, v in state_dict_3.items()])\n",
        "\n",
        "#Initializing weights for decoder_2\n",
        "decoder_4.load_state_dict(state_dict_3, strict = False)\n",
        "\n",
        "#Trying default parameter values for Adam\n",
        "optimizer = optim.Adam(decoder_4.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0nzibi_M0lli",
        "outputId": "67d9944d-b521-4a48-b605-ccb0c3e11fa8"
      },
      "outputs": [],
      "source": [
        "#Training the model\n",
        "train_model(decoder_4, \"decoder_4_2\", training_generator, validation_generator,\n",
        "                device, loss_fn, optimizer, patience = 80, max_epochs = 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwwq_2Ka2cap"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT29xfhgkbvy",
        "outputId": "51ebfa69-f65e-4332-ff9c-a2b79c7ffba9"
      },
      "outputs": [],
      "source": [
        "print('/a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-F2eFt82duL",
        "outputId": "e0b29dd9-4220-4f3a-cc1e-3118188abd8d"
      },
      "outputs": [],
      "source": [
        "decoder_4.load_state_dict(torch.load(save_path + \"decoder_4_2.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LFl6ySgYIx0H",
        "outputId": "7851cc8e-b10c-4d26-bddc-99ec0c3fd045"
      },
      "outputs": [],
      "source": [
        "#Training data\n",
        "plot_generated_imgs(decoder_4, targets_training, features_training_4,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S8ibWr0G2f3I",
        "outputId": "dca142a9-8d03-4c75-f905-3316a9f92606"
      },
      "outputs": [],
      "source": [
        "#Validation data\n",
        "plot_generated_imgs(decoder_4, targets_testing, features_testing_4,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wWDAyOrfQNl"
      },
      "source": [
        "### Getting error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsM1Y0o6fRvy"
      },
      "outputs": [],
      "source": [
        "checkpoint_4_train_err = get_squared_error(decoder_4, features_training_4, targets_training)\n",
        "checkpoint_4_test_err = get_squared_error(decoder_4, features_testing_4, targets_testing)\n",
        "\n",
        "torch.save(checkpoint_4_train_err, err_save_path + \"checkpoint_4_2_train_err.pt\")\n",
        "torch.save(checkpoint_4_test_err, err_save_path + \"checkpoint_4_2_test_err.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLhik5hM_yhK"
      },
      "outputs": [],
      "source": [
        "#freeing up memory\n",
        "del(checkpoint_4_train_err)\n",
        "del(checkpoint_4_test_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqO-QrI39XRM"
      },
      "source": [
        "### Running Resnet on checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DW1dUeu9ZTC"
      },
      "outputs": [],
      "source": [
        "c_4_resnet = decoded_predictions(features_testing_4, decoder_4, resnet)\n",
        "\n",
        "c_4_resnet_loss = F.cross_entropy(c_4_resnet, test_labels)\n",
        "c_4_resnet_preds = F.softmax(c_4_resnet, dim = 1).argmax(dim = 1)\n",
        "c_4_resnet_acc = ((c_4_resnet_preds == test_labels).sum() / 10000).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ojDHpC6h8Y"
      },
      "source": [
        "## Checkpoint 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKUzKFoS6had"
      },
      "outputs": [],
      "source": [
        "#Loading feature tensors\n",
        "features_training_5 = torch.load(data_path + \"c_5_train.pt\")\n",
        "features_testing_5 = torch.load(data_path + \"c_5_test.pt\")\n",
        "\n",
        "# Parameters for the dataloaders\n",
        "params = {'batch_size': 10,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "# Creating datasets and dataloaders\n",
        "training_set = torch.utils.data.TensorDataset(features_training_5, targets_training)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = torch.utils.data.TensorDataset(features_testing_5, targets_testing)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co3Rhl9K-Lb4"
      },
      "outputs": [],
      "source": [
        "#Initializing model and moving it to the GPU\n",
        "decoder_5 = ResNetDecoder(n_blocks = 4, n_channels_in = [512, 256, 128, 64],\n",
        "                          n_channels_out = [256, 128, 64, 64], strides = [2, 2, 2, 1],\n",
        "                          final_stride=1, final_padding = 1,\n",
        "                          output_padding = [1, 1, 1, 0],\n",
        "                          checkpoint_n = 5).to(device)\n",
        "\n",
        "decoder_5 = torch.nn.DataParallel(decoder_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRjFP_-9-VEx"
      },
      "outputs": [],
      "source": [
        "#Loading weights from decoder_4\n",
        "state_dict_4 = decoder_4.state_dict()\n",
        "\n",
        "#Initializing weights for decoder_5\n",
        "decoder_5.load_state_dict(state_dict_4, strict = False)\n",
        "\n",
        "#Trying default parameter values for Adam\n",
        "optimizer = optim.Adam(decoder_5.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mplRicB7-f6j",
        "outputId": "9dd55b8f-6ef8-48c5-81d5-c6ecfb3db6bf"
      },
      "outputs": [],
      "source": [
        "#Training the model\n",
        "decoder_5_train_loss, decoder_5_test_loss = train_model(decoder_5, \"decoder_5_3\", training_generator,\n",
        "                                                        validation_generator, device, loss_fn,\n",
        "                                                        optimizer, patience = 200, max_epochs = 300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMqk402v-uOI"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K75zHPL3m_A7"
      },
      "outputs": [],
      "source": [
        "#This needs to run to ensure that unpooling weights are initialized\n",
        "init = decoder_5(torch.zeros(10, 512, 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY-RScqW-ve5"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  decoder_5.load_state_dict(torch.load(save_path + \"decoder_5_3.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d5O_6KUq-za4",
        "outputId": "a044e21b-4a81-415e-bda5-86c65a64f286"
      },
      "outputs": [],
      "source": [
        "#Training data\n",
        "plot_generated_imgs(decoder_5, targets_training, features_training_5,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RxqKqjD2_DrB",
        "outputId": "ff20d2fe-8ef9-46e5-db93-c693f352e141"
      },
      "outputs": [],
      "source": [
        "#Validation data\n",
        "plot_generated_imgs(decoder_5, targets_testing, features_testing_5,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmO74vdH_I_V"
      },
      "source": [
        "### Getting errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5NT7EhN_ILR"
      },
      "outputs": [],
      "source": [
        "checkpoint_5_train_err = get_squared_error(decoder_5, features_training_5, targets_training)\n",
        "checkpoint_5_test_err = get_squared_error(decoder_5, features_testing_5, targets_testing)\n",
        "\n",
        "torch.save(checkpoint_5_train_err, err_save_path + \"checkpoint_5_3_train_err.pt\")\n",
        "torch.save(checkpoint_5_test_err, err_save_path + \"checkpoint_5_3_test_err.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDowZAwp_0d1"
      },
      "outputs": [],
      "source": [
        "#freeing up memory\n",
        "del(checkpoint_5_train_err)\n",
        "del(checkpoint_5_test_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCUSwjbG-B6D"
      },
      "source": [
        "### Running resnet on checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8Ss97N3-D7Y"
      },
      "outputs": [],
      "source": [
        "c_5_resnet = decoded_predictions(features_testing_5, decoder_5, resnet)\n",
        "\n",
        "c_5_resnet_loss = F.cross_entropy(c_5_resnet, test_labels)\n",
        "c_5_resnet_preds = F.softmax(c_5_resnet, dim = 1).argmax(dim = 1)\n",
        "c_5_resnet_acc = ((c_5_resnet_preds == test_labels).sum() / 10000).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EEBU63--Um4"
      },
      "outputs": [],
      "source": [
        "del(features_training_5)\n",
        "#del(features_testing_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBnrfehIN65D"
      },
      "source": [
        "## Checkpoint 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpgm_SDHNygN"
      },
      "outputs": [],
      "source": [
        "#Loading feature tensors\n",
        "features_training_6 = torch.load(data_path + \"c_6_train.pt\")\n",
        "features_testing_6 = torch.load(data_path + \"c_6_test.pt\")\n",
        "\n",
        "# Parameters for the dataloaders\n",
        "params = {'batch_size': 10,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "# Creating datasets and dataloaders\n",
        "training_set = torch.utils.data.TensorDataset(features_training_6, targets_training)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = torch.utils.data.TensorDataset(features_testing_6, targets_testing)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY-vamjaHx83"
      },
      "outputs": [],
      "source": [
        "#Initializing model and moving it to the GPU\n",
        "decoder_6 = ResNetDecoder(n_blocks = 4, n_channels_in = [512, 256, 128, 64],\n",
        "                          n_channels_out = [256, 128, 64, 64], strides = [2, 2, 2, 1],\n",
        "                          final_stride=1, final_padding = 1,\n",
        "                          output_padding = [1, 1, 1, 0],\n",
        "                          checkpoint_n = 6).to(device)\n",
        "\n",
        "decoder_6 = torch.nn.DataParallel(decoder_6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2hEoQqnODvM"
      },
      "outputs": [],
      "source": [
        "#Loading weights from decoder_5\n",
        "state_dict_5 = decoder_5.state_dict()\n",
        "\n",
        "#Initializing weights for decoder_2\n",
        "decoder_6.load_state_dict(state_dict_5, strict = False)\n",
        "\n",
        "#Trying default parameter values for Adam\n",
        "optimizer = optim.Adam(decoder_6.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ohBsEzzVAOsC",
        "outputId": "92f76cc4-e720-464d-96a2-957e130976fa"
      },
      "outputs": [],
      "source": [
        "#Training the model\n",
        "train_model(decoder_6, \"decoder_6_8\", training_generator, validation_generator,\n",
        "                device, loss_fn, optimizer, patience = 200, max_epochs = 300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqwEWdmuOLUi"
      },
      "source": [
        "### Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjQNCxKvhPAW"
      },
      "outputs": [],
      "source": [
        "#This needs to run to ensure that unpooling weights are initialized\n",
        "init = decoder_6(torch.zeros(10, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3VETfVbI0_R"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  decoder_6.load_state_dict(torch.load(save_path + \"decoder_6_8.pt\", map_location = device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QZBccFXxytfx",
        "outputId": "bfa29a24-717a-4b60-a52f-80011fbbb61c"
      },
      "outputs": [],
      "source": [
        "#Training data\n",
        "plot_generated_imgs(decoder_6, targets_training, features_training_6,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FfeXCr8SONb-",
        "outputId": "8169e539-bcf5-45f6-d814-f7dd77b0fe48"
      },
      "outputs": [],
      "source": [
        "#Validation data\n",
        "plot_generated_imgs(decoder_6, targets_testing, features_testing_6,\n",
        "                        num_images_to_plot = 10, figsize = (16, 32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RchQ3vLfYdI"
      },
      "source": [
        "### Getting errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e-MIo-qfZ7N"
      },
      "outputs": [],
      "source": [
        "checkpoint_6_train_err = get_squared_error(decoder_6, features_training_6, targets_training)\n",
        "checkpoint_6_test_err = get_squared_error(decoder_6, features_testing_6, targets_testing)\n",
        "\n",
        "torch.save(checkpoint_6_train_err, err_save_path + \"checkpoint_6_8_train_err.pt\")\n",
        "torch.save(checkpoint_6_test_err, err_save_path + \"checkpoint_6_8_test_err.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "i36KLs-y_6up",
        "outputId": "f41c12fb-3565-460e-9327-f117c72c7ad6"
      },
      "outputs": [],
      "source": [
        "#freeing up memory\n",
        "del(checkpoint_6_train_err)\n",
        "del(checkpoint_6_test_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6cuTno7-iHf"
      },
      "source": [
        "### Running resnet on checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekyqD_Ks-kUq"
      },
      "outputs": [],
      "source": [
        "c_6_resnet = decoded_predictions(features_testing_6, decoder_6, resnet)\n",
        "\n",
        "c_6_resnet_loss = F.cross_entropy(c_6_resnet, test_labels)\n",
        "c_6_resnet_preds = F.softmax(c_6_resnet, dim = 1).argmax(dim = 1)\n",
        "c_6_resnet_acc = ((c_6_resnet_preds == test_labels).sum() / 10000).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qdvMUmf-wKs"
      },
      "outputs": [],
      "source": [
        "resnet_losses = torch.tensor([c_1_resnet_loss,\n",
        "                              c_2_resnet_loss,\n",
        "                              c_3_resnet_loss,\n",
        "                              c_4_resnet_loss,\n",
        "                              c_5_resnet_loss,\n",
        "                              c_6_resnet_loss])\n",
        "\n",
        "resnet_acc = torch.tensor([c_1_resnet_acc,\n",
        "                           c_2_resnet_acc,\n",
        "                           c_3_resnet_acc,\n",
        "                           c_4_resnet_acc,\n",
        "                           c_5_resnet_acc,\n",
        "                           c_6_resnet_acc,])\n",
        "\n",
        "torch.save(resnet_losses,\n",
        "           \"/content/drive/My Drive/Colab Notebooks/Examensarbete/resnet_losses.pt\")\n",
        "\n",
        "torch.save(resnet_acc,\n",
        "           \"/content/drive/My Drive/Colab Notebooks/Examensarbete/resnet_acc.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KSQkX6mVxLL"
      },
      "source": [
        "# Decoding Each Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6L0ycpyXsRQ"
      },
      "outputs": [],
      "source": [
        "#Function for decoding individual embeddings into images\n",
        "import numpy as np\n",
        "\n",
        "def decode_image(model, observation, show = False, device = \"cpu\"):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    decoded_image = model(observation.unsqueeze(0))\n",
        "\n",
        "  if show == True:\n",
        "    # The tensor is of dimensions (3, 32, 32), but imshow expects (32, 32, 3)\n",
        "    decoded_image = decoded_image.squeeze(0).permute(1, 2, 0)\n",
        "\n",
        "    #Normalizing pixel values to 0-1\n",
        "    decoded_image = (decoded_image - decoded_image.min()) / (decoded_image.max() - decoded_image.min())\n",
        "    decoded_image = decoded_image.to(\"cpu\")\n",
        "    plt.imshow(decoded_image)\n",
        "    plt.show()\n",
        "\n",
        "  else:\n",
        "    return decoded_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oRrLf1Ajg5b"
      },
      "outputs": [],
      "source": [
        "def decode_checkpoint(data, indices, decoder):\n",
        "  num_images = len(indices)\n",
        "  decoded_imgs = torch.zeros(len(indices), 3, 32, 32)\n",
        "\n",
        "  for i in range(num_images):\n",
        "    decoded_imgs[i] = decode_image(decoder, data[indices[i]], show = False)\n",
        "\n",
        "  return decoded_imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5rXMmAUV2h0"
      },
      "outputs": [],
      "source": [
        "test_probs = F.softmax(features_testing_6, dim = 1)\n",
        "\n",
        "#Tensor containing the probability that the network assigns to the correct class\n",
        "correct_class_probs = torch.zeros(10000)\n",
        "for i in range(10000):\n",
        "  correct_class_probs[i] = test_probs[i, test_labels[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqSLMZ2TcWcq"
      },
      "outputs": [],
      "source": [
        "classes = [\"airplane\",\n",
        "           \"automobile\",\n",
        "           \"bird\",\n",
        "           \"cat\",\n",
        "           \"deer\",\n",
        "           \"dog\",\n",
        "           \"frog\",\n",
        "           \"horse\",\n",
        "           \"ship\",\n",
        "           \"truck\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edicoVKjnQxE"
      },
      "outputs": [],
      "source": [
        "test_labels_list = list(test_labels.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN-szdOM1eMC"
      },
      "source": [
        "## High probability observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no-djhKr0AGC"
      },
      "outputs": [],
      "source": [
        "#Getting indices of observations that were easy to predict\n",
        "not_high_probs_idx = correct_class_probs < 0.9\n",
        "high_probs_labels = test_labels.clone().detach()\n",
        "high_probs_labels[not_high_probs_idx] = -1 #Setting low prob. observations to -1\n",
        "high_probs_labels = list(high_probs_labels.numpy())\n",
        "\n",
        "high_probs_idx = [high_probs_labels.index(elem) for elem in set(test_labels_list)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZrBFq8ehvOH"
      },
      "outputs": [],
      "source": [
        "num_checkpoints = 7\n",
        "\n",
        "#Indices of the images we wish to show\n",
        "\n",
        "#First occurence of each class\n",
        "#image_idx = [test_labels_list.index(elem) for elem in set(test_labels_list)]\n",
        "\n",
        "image_idx = high_probs_idx\n",
        "num_images = len(image_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzU7lOgc9Pbh"
      },
      "outputs": [],
      "source": [
        "class_prob = correct_class_probs[image_idx].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PmpZjxenIyf"
      },
      "outputs": [],
      "source": [
        "#Creating tensors containing decoded images\n",
        "c_1_decoded = decode_checkpoint(features_testing_1, image_idx, decoder_1)\n",
        "c_2_decoded = decode_checkpoint(features_testing_2, image_idx, decoder_2)\n",
        "c_3_decoded = decode_checkpoint(features_testing_3, image_idx, decoder_3)\n",
        "c_4_decoded = decode_checkpoint(features_testing_4, image_idx, decoder_4)\n",
        "c_5_decoded = decode_checkpoint(features_testing_5, image_idx, decoder_5)\n",
        "c_6_decoded = decode_checkpoint(features_testing_6, image_idx, decoder_6)\n",
        "\n",
        "images_to_plot = torch.zeros(num_checkpoints, num_images, 3, 32, 32)\n",
        "images_to_plot[0] = targets_testing[tuple(image_idx), :, :, :]\n",
        "images_to_plot[1] = c_1_decoded\n",
        "images_to_plot[2] = c_2_decoded\n",
        "images_to_plot[3] = c_3_decoded\n",
        "images_to_plot[4] = c_4_decoded\n",
        "images_to_plot[5] = c_5_decoded\n",
        "images_to_plot[6] = c_6_decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1Mulidfquv4"
      },
      "outputs": [],
      "source": [
        "#Predicting decodings with resnet\n",
        "resnet_out = torch.zeros(num_images, num_checkpoints, 10)\n",
        "resnet.eval()\n",
        "for i in range(num_images):\n",
        "  for c in range(num_checkpoints):\n",
        "    with torch.no_grad():\n",
        "      resnet_out[i, c] = resnet(images_to_plot[c, i].unsqueeze(0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsWO7fFYw_YD"
      },
      "outputs": [],
      "source": [
        "#Getting resnet probabilities\n",
        "resnet_probs = F.softmax(resnet_out, dim = 2)\n",
        "resnet_preds = resnet_probs.argmax(dim = 2)\n",
        "\n",
        "#Getting resnet predictions as strings\n",
        "resnet_preds_str = np.empty((num_images, num_checkpoints), dtype = \"U10\")\n",
        "\n",
        "for i in range(num_images):\n",
        "  for c in range(num_checkpoints):\n",
        "    resnet_preds_str[i, c] = classes[resnet_preds[i, c]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "NaMpoJDscAYK",
        "outputId": "6cf6dded-adec-41b0-845e-9d8b321d1748"
      },
      "outputs": [],
      "source": [
        "#Plotting decodings\n",
        "fig, axes = plt.subplots(num_images, num_checkpoints, figsize = (15, 6))\n",
        "\n",
        "for i in range(0, num_images):\n",
        "  current_class = test_labels[image_idx[i]]\n",
        "\n",
        "  axes[i, 0].set_ylabel(classes[current_class],# + \"\\np = \" + str(round(class_prob[i], 4)),\n",
        "                        rotation=0, size='medium',\n",
        "                        ha = \"right\", va = \"center\", weight = \"bold\")\n",
        "  for j in range(0, num_checkpoints):\n",
        "    image = images_to_plot[j, i]\n",
        "    image = image.permute(1, 2, 0).to(\"cpu\")\n",
        "    image = (image - image.min()) / (image.max() - image.min())\n",
        "    axes[i, j].imshow(image)\n",
        "    axes[i, j].spines['top'].set_visible(False)\n",
        "    axes[i, j].spines['right'].set_visible(False)\n",
        "    axes[i, j].spines['bottom'].set_visible(False)\n",
        "    axes[i, j].spines['left'].set_visible(False)\n",
        "    axes[i, j].set_xlabel(resnet_preds_str[i, j].item(),\n",
        "                          rotation=0, ha = \"center\", size = \"small\")#, size='large'\n",
        "\n",
        "axes[0, 0].set_title(\"Original\", rotation=0, size='medium', ha = \"center\",\n",
        "                     weight = \"bold\")\n",
        "\n",
        "for k in range(1, num_checkpoints):\n",
        "  axes[0, k].set_title(\"CP \" + str(k), rotation=0, size='medium',\n",
        "                       ha = \"center\", weight = \"bold\")\n",
        "\n",
        "# Remove padding and margin around the subplots\n",
        "plt.subplots_adjust(left=0, right=1, bottom=0, top=1, wspace=-0.93, hspace=0.5)\n",
        "\n",
        "# Remove the white space around the figure\n",
        "#plt.tight_layout(w_pad = -5, h_pad=0)\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLamqR221jl_"
      },
      "source": [
        "## Low probability observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AYdNghppuvQ"
      },
      "outputs": [],
      "source": [
        "#Getting indices of observations that were hard to predict\n",
        "not_low_probs_idx = correct_class_probs > 0.5\n",
        "low_probs_labels = test_labels.clone().detach()\n",
        "low_probs_labels[not_low_probs_idx] = -1 #Setting high prob. observations to -1\n",
        "low_probs_labels = list(low_probs_labels.numpy())\n",
        "\n",
        "low_probs_idx = [low_probs_labels.index(elem) for elem in set(test_labels_list)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWvcF6kM1u4r"
      },
      "outputs": [],
      "source": [
        "num_checkpoints = 7\n",
        "\n",
        "#Indices of the images we wish to show\n",
        "\n",
        "#First occurence of each class\n",
        "#image_idx = [test_labels_list.index(elem) for elem in set(test_labels_list)]\n",
        "\n",
        "image_idx = low_probs_idx\n",
        "num_images = len(image_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfVJKBzU26eI"
      },
      "outputs": [],
      "source": [
        "class_prob = correct_class_probs[image_idx].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPMRvp991xl0"
      },
      "outputs": [],
      "source": [
        "#Creating tensors containing decoded images\n",
        "c_1_decoded = decode_checkpoint(features_testing_1, image_idx, decoder_1)\n",
        "c_2_decoded = decode_checkpoint(features_testing_2, image_idx, decoder_2)\n",
        "c_3_decoded = decode_checkpoint(features_testing_3, image_idx, decoder_3)\n",
        "c_4_decoded = decode_checkpoint(features_testing_4, image_idx, decoder_4)\n",
        "c_5_decoded = decode_checkpoint(features_testing_5, image_idx, decoder_5)\n",
        "c_6_decoded = decode_checkpoint(features_testing_6, image_idx, decoder_6)\n",
        "\n",
        "images_to_plot = torch.zeros(num_checkpoints, num_images, 3, 32, 32)\n",
        "images_to_plot[0] = targets_testing[tuple(image_idx), :, :, :]\n",
        "images_to_plot[1] = c_1_decoded\n",
        "images_to_plot[2] = c_2_decoded\n",
        "images_to_plot[3] = c_3_decoded\n",
        "images_to_plot[4] = c_4_decoded\n",
        "images_to_plot[5] = c_5_decoded\n",
        "images_to_plot[6] = c_6_decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjgSJXcD13aR"
      },
      "outputs": [],
      "source": [
        "#Predicting decodings with resnet\n",
        "resnet_out = torch.zeros(num_images, num_checkpoints, 10)\n",
        "resnet.eval()\n",
        "for i in range(num_images):\n",
        "  for c in range(num_checkpoints):\n",
        "    with torch.no_grad():\n",
        "      resnet_out[i, c] = resnet(images_to_plot[c, i].unsqueeze(0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_Qz6Cku14ML"
      },
      "outputs": [],
      "source": [
        "#Getting resnet probabilities\n",
        "resnet_probs = F.softmax(resnet_out, dim = 2)\n",
        "resnet_preds = resnet_probs.argmax(dim = 2)\n",
        "\n",
        "#Getting resnet predictions as strings\n",
        "resnet_preds_str = np.empty((num_images, num_checkpoints), dtype = \"U10\")\n",
        "\n",
        "for i in range(num_images):\n",
        "  for c in range(num_checkpoints):\n",
        "    resnet_preds_str[i, c] = classes[resnet_preds[i, c]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "u0xFJDhg17FN",
        "outputId": "d9ad0ebb-4321-44ea-a1e1-8b4bc00143d3"
      },
      "outputs": [],
      "source": [
        "#Plotting decodings\n",
        "fig, axes = plt.subplots(num_images, num_checkpoints, figsize = (15, 6))\n",
        "\n",
        "for i in range(0, num_images):\n",
        "  current_class = test_labels[image_idx[i]]\n",
        "\n",
        "  axes[i, 0].set_ylabel(classes[current_class], # + \"\\np = \" + str(round(class_prob[i], 4)),\n",
        "                        rotation=0, size='medium',\n",
        "                        ha = \"right\", va = \"center\", weight = \"bold\")\n",
        "  for j in range(0, num_checkpoints):\n",
        "    image = images_to_plot[j, i]\n",
        "    image = image.permute(1, 2, 0).to(\"cpu\")\n",
        "    image = (image - image.min()) / (image.max() - image.min())\n",
        "    axes[i, j].imshow(image)\n",
        "    axes[i, j].spines['top'].set_visible(False)\n",
        "    axes[i, j].spines['right'].set_visible(False)\n",
        "    axes[i, j].spines['bottom'].set_visible(False)\n",
        "    axes[i, j].spines['left'].set_visible(False)\n",
        "    axes[i, j].set_xlabel(resnet_preds_str[i, j].item(),\n",
        "                          rotation=0, ha = \"center\", size = \"small\")#, size='large'\n",
        "\n",
        "axes[0, 0].set_title(\"Original\", rotation=0, size='medium', ha = \"center\",\n",
        "                     weight = \"bold\")\n",
        "\n",
        "for k in range(1, num_checkpoints):\n",
        "  axes[0, k].set_title(\"CP \" + str(k), rotation=0, size='medium',\n",
        "                       ha = \"center\", weight = \"bold\")\n",
        "\n",
        "# Remove padding and margin around the subplots\n",
        "plt.subplots_adjust(left=0, right=1, bottom=0, top=1, wspace=-0.93, hspace=0.5)\n",
        "\n",
        "# Remove the white space around the figure\n",
        "#plt.tight_layout(w_pad = -5, h_pad=0)\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbEEWC7FiZIg"
      },
      "source": [
        "## Decoding artificial final layer values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9orvwcupL3X"
      },
      "outputs": [],
      "source": [
        "#Function for decoding individual embeddings into images\n",
        "import numpy as np\n",
        "\n",
        "def decode_image(model, observation, show = False, device = \"cpu\"):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    decoded_image = model(observation.unsqueeze(0))\n",
        "\n",
        "  if show == True:\n",
        "    # The tensor is of dimensions (3, 32, 32), but imshow expects (32, 32, 3)\n",
        "    decoded_image = decoded_image.squeeze(0).permute(1, 2, 0)\n",
        "\n",
        "    #Normalizing pixel values to 0-1\n",
        "    decoded_image = (decoded_image - decoded_image.min()) / (decoded_image.max() - decoded_image.min())\n",
        "    decoded_image = decoded_image.to(\"cpu\")\n",
        "    plt.imshow(decoded_image)\n",
        "    plt.show()\n",
        "\n",
        "  else:\n",
        "    return decoded_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CGnS5HC4FTt",
        "outputId": "656a9b27-bfa4-43f3-eb18-6715fd20cbb5"
      },
      "outputs": [],
      "source": [
        "test_obs = features_testing_6[0]\n",
        "test_obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBjb6WnrA57g"
      },
      "outputs": [],
      "source": [
        "test_obs = torch.zeros(10)\n",
        "test_obs[3] = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "-D2NlKawIj_V",
        "outputId": "fe0a03ef-c666-46c4-e215-26a7578d77ba"
      },
      "outputs": [],
      "source": [
        "decode_image(decoder_6, test_obs, show = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSEGGZ8Zih9h"
      },
      "outputs": [],
      "source": [
        "#Creating artificial data for each class\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "num_images = 15\n",
        "\n",
        "classes = [\"airplane\",\n",
        "           \"automobile\",\n",
        "           \"bird\",\n",
        "           \"cat\",\n",
        "           \"deer\",\n",
        "           \"dog\",\n",
        "           \"frog\",\n",
        "           \"horse\",\n",
        "           \"ship\",\n",
        "           \"truck\"]\n",
        "\n",
        "artificial_data = torch.zeros(num_classes, num_images, 10)\n",
        "for i in range(num_classes):\n",
        "  artificial_data[i, :, i] = torch.arange(-2, (num_images - 2), 1)# - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A5_r062oP0A"
      },
      "outputs": [],
      "source": [
        "#Decoding artificial data\n",
        "decoded_tensor = torch.zeros(num_classes, num_images, 3, 32, 32)\n",
        "for i in range(num_classes):\n",
        "  for j in range(num_images):\n",
        "    decoded_tensor[i, j] = decode_image(decoder_6, artificial_data[i, j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD7r8djgpn5D"
      },
      "outputs": [],
      "source": [
        "#Predicting decodings with resnet\n",
        "resnet_artificial_out = torch.zeros(num_classes, num_images, 10)\n",
        "resnet.eval()\n",
        "for i in range(num_classes):\n",
        "  for j in range(num_images):\n",
        "    with torch.no_grad():\n",
        "      resnet_artificial_out[i, j] = resnet(decoded_tensor[i, j].unsqueeze(0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsB-3mFl_qyS"
      },
      "outputs": [],
      "source": [
        "resnet_artificial_probs = F.softmax(resnet_artificial_out, dim = 2)\n",
        "resnet_artificial_preds = resnet_artificial_probs.argmax(dim = 2)\n",
        "resnet_artificial_preds_str = np.empty((num_classes, num_images), dtype = \"U10\")\n",
        "\n",
        "for i in range(num_classes):\n",
        "  for j in range(num_images):\n",
        "    resnet_artificial_preds_str[i, j] = classes[resnet_artificial_preds[i, j]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "1u9t_n9fILGQ",
        "outputId": "306a551a-5bfc-4b7c-dc6f-055414d640ac"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(num_classes, num_images, figsize = (15, 6))\n",
        "\n",
        "for i in range(0, num_classes):\n",
        "  axes[i, 0].set_ylabel(classes[i], rotation=0, size='medium', ha = \"right\",\n",
        "                        weight = \"bold\")\n",
        "  for j in range(0, num_images):\n",
        "    image = decoded_tensor[i, j]\n",
        "    image = image.permute(1, 2, 0).to(\"cpu\")\n",
        "    image = (image - image.min()) / (image.max() - image.min())\n",
        "    axes[i, j].imshow(image)\n",
        "    axes[i, j].spines['top'].set_visible(False)\n",
        "    axes[i, j].spines['right'].set_visible(False)\n",
        "    axes[i, j].spines['bottom'].set_visible(False)\n",
        "    axes[i, j].spines['left'].set_visible(False)\n",
        "    axes[i, j].set_xlabel(resnet_artificial_preds_str[i, j].item(),\n",
        "                          rotation=0, ha = \"center\", size = \"small\")\n",
        "\n",
        "for k in range(num_images):\n",
        "  axes[0, k].set_title(k - 2, rotation=0, size='medium', ha = \"center\",\n",
        "                       weight = \"bold\")\n",
        "\n",
        "# Remove padding and margin around the subplots\n",
        "plt.subplots_adjust(left=0, right=1, bottom=0, top=1, wspace=-0.92, hspace=0.5)\n",
        "\n",
        "# Remove the white space around the figure\n",
        "#plt.tight_layout(w_pad = -5, h_pad=0)\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85qnEO3i47vu"
      },
      "outputs": [],
      "source": [
        "cat_varied_data = torch.zeros((2, 12, 10))\n",
        "cat_varied_data[0, :, 5] = torch.tensor(0.4)\n",
        "cat_varied_data[:, :, 3] = torch.arange(-2.0, 10.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "M15WYeav6ua-",
        "outputId": "55a77df9-0685-480e-d3cc-07d8e3e985b2"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 12, figsize = (15, 6))\n",
        "\n",
        "for i in range(0, 2):\n",
        "  axes[i, 0].set_ylabel(f\"Dog: {round(cat_varied_data[i, 0, 5].item(), 1)}\",\n",
        "                        rotation = 0, ha = \"right\")\n",
        "  for j in range(0, 12):\n",
        "    image = decode_image(decoder_6, cat_varied_data[i, j])\n",
        "    axes[i, j].imshow(image.unsqueeze(0).permute(1, 2, 0))\n",
        "    axes[i, j].spines['top'].set_visible(False)\n",
        "    axes[i, j].spines['right'].set_visible(False)\n",
        "    axes[i, j].spines['bottom'].set_visible(False)\n",
        "    axes[i, j].spines['left'].set_visible(False)\n",
        "    axes[i, j].set_xlabel(f\"Cat: {cat_varied_data[i, j, 3]}\")\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51csH9Krz0Le"
      },
      "source": [
        "## Generating images between dog and cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9ZDSXtnhpge"
      },
      "outputs": [],
      "source": [
        "def get_mix(class1, class2, max_val = 9, show = True):\n",
        "  classes = {\"airplane\" : 0,\n",
        "             \"automobile\" : 1,\n",
        "             \"bird\" : 2,\n",
        "             \"cat\" : 3,\n",
        "             \"deer\" : 4,\n",
        "             \"dog\" : 5,\n",
        "             \"frog\" : 6,\n",
        "             \"horse\": 7,\n",
        "             \"ship\" : 8,\n",
        "             \"truck\" : 9\n",
        "           }\n",
        "\n",
        "  mix_tensor = torch.zeros(max_val, 10)\n",
        "  mix_tensor[:, classes[class2]] = torch.arange(0.0, max_val) #class2 values\n",
        "  mix_tensor[:, classes[class1]] = -1 * mix_tensor[:, classes[class2]] + (max_val - 1)\n",
        "\n",
        "  if show == True:\n",
        "    fig, axes = plt.subplots(1, max_val, figsize = (15, 6))\n",
        "    for i in range(0, max_val):\n",
        "      image = decode_image(decoder_6, mix_tensor[i])\n",
        "      axes[i].imshow(image)\n",
        "      axes[i].axis(\"off\")\n",
        "      val1 = mix_tensor[i, classes[class1]].item()\n",
        "      val2 = mix_tensor[i, classes[class2]].item()\n",
        "      axes[i].set_title(f\"{class1}: {val1}\\n{class2}: {val2}\",\n",
        "                        fontsize=12, ha = \"center\", va = \"top\")\n",
        "    plt.show()\n",
        "\n",
        "  else:\n",
        "    return mix_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5zMOHTeF7Dk"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "def get_mix_animation(class1, class2, max_val = 9, show = True):\n",
        "  classes = {\"airplane\" : 0,\n",
        "             \"automobile\" : 1,\n",
        "             \"bird\" : 2,\n",
        "             \"cat\" : 3,\n",
        "             \"deer\" : 4,\n",
        "             \"dog\" : 5,\n",
        "             \"frog\" : 6,\n",
        "             \"horse\": 7,\n",
        "             \"ship\" : 8,\n",
        "             \"truck\" : 9\n",
        "           }\n",
        "\n",
        "  mix_tensor = torch.zeros(max_val * 2, 10)\n",
        "  mix_tensor[:, classes[class2]] = torch.arange(0.0, max_val, 0.5) #class2 values\n",
        "  mix_tensor[:, classes[class1]] = -1 * mix_tensor[:, classes[class2]] + (max_val - 1)\n",
        "\n",
        "  res_tensor = torch.zeros(max_val * 2, 32, 32, 3)\n",
        "  for i in range(max_val * 2):\n",
        "    res_tensor[i] = decode_image(decoder_6, mix_tensor[i])\n",
        "\n",
        "  fig =px.imshow(res_tensor, animation_frame = 0)\n",
        "  if show == True:\n",
        "    fig.show()\n",
        "  else:\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "iT0GYVrzODF2",
        "outputId": "0f359e77-aeba-4af8-9dc4-dcb653f3c88e"
      },
      "outputs": [],
      "source": [
        "animation = get_mix_animation(\"cat\", \"dog\", show = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "k0SgblVxi_QA",
        "outputId": "ef0f5427-0b0c-4a00-c721-56d55bbb75b6"
      },
      "outputs": [],
      "source": [
        "get_mix(\"cat\", \"dog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "jZDL93rxjEKa",
        "outputId": "6d1ab0ea-2d44-49a8-bb8a-bdd42bcedbd7"
      },
      "outputs": [],
      "source": [
        "get_mix(\"airplane\", \"ship\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "P3EQJEwtjQyI",
        "outputId": "981d7652-c297-4e23-ee72-ba3b82aebc28"
      },
      "outputs": [],
      "source": [
        "get_mix(\"bird\", \"horse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "6XJL18AcjafJ",
        "outputId": "ddd672f2-eeb3-4675-ea63-61745196ad0b"
      },
      "outputs": [],
      "source": [
        "get_mix(\"ship\", \"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "a-ErWQsEkINc",
        "outputId": "cbe05933-1a17-4dc0-958f-cab409985825"
      },
      "outputs": [],
      "source": [
        "get_mix(\"cat\", \"horse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "KrfZYGIrncRL",
        "outputId": "14982f6b-778a-403e-95db-d27dc69df3d2"
      },
      "outputs": [],
      "source": [
        "get_mix(\"automobile\", \"horse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "_nNDp7cBnhXf",
        "outputId": "262e8d95-27f3-4ee0-acf4-7b11d5f99a2f"
      },
      "outputs": [],
      "source": [
        "get_mix(\"cat\", \"frog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdjcR3v91gCd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
